defaults:
  - model: groundvqa_b
  - _self_
  - override hydra/job_logging: none
  - override hydra/hydra_logging: none

# runtime parameters
jid: ${oc.env:SLURM_JOB_ID}
job_type: ${job_type:}  # debug or batch
YY: ${now:%Y}
mm: ${now:%m}  # month
dd: ${now:%d}  # day
runtime_outdir: ${runtime_outdir:}
base_lr: 0.0001
total_bsz: ${eval:'${dataset.batch_size} * ${oc.env:SLURM_GPUS_ON_NODE,8} * ${oc.env:SLURM_JOB_NUM_NODES,1}'}
total_steps: ${eval:'${trainer.max_epochs} * ${dataset.num_train_samples} // ${oc.env:SLURM_GPUS_ON_NODE,8} // ${dataset.batch_size}'}
load_nlq_head: True
load_decoder: True
run_type: 'Train'
checkpoint_path: null

dataset:
  data_dir: '/data/soyeonhong/nlq/nlq_lightning/data/unified'
  ann_dir: '/data/datasets/ego4d_data/v2/annotations'
  feature_type: egovlp_internvideo
  feature_dim: 2304
  max_v_len: 1200

  qa_train_splits: []
  nlq_train_splits: ['NLQ_train']
  test_splits: ['NLQ_val']
  closeqa_weight: 50

  tokenizer_path: google/flan-t5-small

  num_workers: 4
  batch_size: 6

  num_train_samples: 13847

trainer:
  detect_anomaly: True
  max_epochs: 100
  accumulate_grad_batches: 1
  auto_resume: False
  gpus: ${oc.env:SLURM_GPUS_ON_NODE,8}
  log_every_n_steps: 1
  auto_lr_find: False
  enable_progress_bar: True
  monitor_variable: val_ROUGE
  monitor_mode: max
  find_unused_parameters: False
  precision: bf16
  val: False  # test on the val set
  gradient_clip_val: 1.0
  save_nlq_results: null
  deterministic: True
  ignore_existing_checkpoints: True
  lr_find_kwargs: {'min_lr': 5e-06, 'max_lr': 0.01}
  random_seed: 42
  test_only: False
  reset_early_stopping_criterion: False
  logger:
    - _target_: pytorch_lightning.loggers.WandbLogger
      project: 'ltvu_NLQ'
      entity: 'team-khu'
      group: 'base'  # for grouping runs (does not mean an organization)
      job_type: ${job_type}  # debug or batch
      name: sy-${jid}  # displayname
      tags: []  # for filtering
      notes: null  # real note, a log string
      save_dir: ${runtime_outdir}  # logs will be saved under THIS/wandb
      log_model: False    # as we use custom checkpointing
  
optim:
  optimizer:
    _target_: torch.optim.AdamW
    lr: ${eval:'${base_lr} / 128 * ${total_bsz}'} # 0.0001 / 128 (official bsz) * (our bsz)
    weight_decay: 0.0
  freeze: [ ]
  lr_scheduler: False

hydra:
  run:
    dir: ./outputs/${job_type}/${YY}-${mm}-${dd}/${jid}
